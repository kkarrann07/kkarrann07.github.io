<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>ChechIT ‚Äì AR Try‚ÄëOn with 3D Model (UI preserved)</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      background: #f7f7f7;
      margin: 0;
      padding: 0;
      text-align: center;
    }
    header {
      background: #222;
      color: #fff;
      padding: 1rem;
      font-size: 1.4rem;
      font-weight: bold;
    }
    section {
      padding: 2rem;
    }
    .ar-container {
      position: relative;
      width: 640px;
      height: 480px;
      margin: auto;
      border-radius: 12px;
      overflow: hidden;
      background: #000; /* fallback while video loads */
    }
    video {
      position: absolute;
      top: 0;
      left: 0;
      width: 640px;
      height: 480px;
      border-radius: 12px;
      transform: scaleX(-1); /* mirror for selfie view */
      z-index: 1;
      object-fit: cover;
    }
    #three-canvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 640px;
      height: 480px;
      border-radius: 12px;
      z-index: 2; /* on top of video */
      pointer-events: none; /* allow clicks to pass through, if needed */
    }
    input[type="file"] {
      margin-top: 10px;
    }
    .static-shirt {
      margin-top: 1rem;
      perspective: 800px;
      width: 320px;
      margin-left: auto;
      margin-right: auto;
      user-select: none;
    }
    .rotator {
      width: 100%;
      height: 400px;
      border-radius: 12px;
      border: 1px solid #ccc;
      overflow: hidden;
      background: #fff;
      display: flex;
      justify-content: center;
      align-items: center;
      cursor: grab;
      transition: transform 0.1s ease-out;
    }
    .rotator img {
      max-width: 100%;
      max-height: 100%;
      pointer-events: none;
      user-select: none;
      border-radius: 12px;
      backface-visibility: hidden;
      transform-style: preserve-3d;
    }
    .rotator:active {
      cursor: grabbing;
    }
  </style>
</head>
<body>
  <header>üëó ChechIT ‚Äì AR Try‚ÄëOn with 3D Model</header>

  <!-- Other sections remain as your original code -->
  <section>
    <h2>üîç AI Fashion Search</h2>
    <p>Use our Hugging Face-powered model to search clothing with AI embeddings.</p>
    <iframe src="https://kkarrann07-Fashion.hf.space" width="100%" height="650"></iframe>
  </section>

  <section>
    <h2>üñºÔ∏è Upload Your Clothing Image / Model</h2>
    <p>Choose a shirt model (.glb/.gltf) or transparent PNG (fallback).</p>
    <input type="file" id="uploadModel" accept=".glb,.gltf,image/*" />
    <div class="static-shirt">
      <p>üì¶ Preview / Catalog Viewer:</p>
      <div class="rotator" id="rotator">
        <img id="staticPreview" src="" alt="Preview" />
      </div>
    </div>
  </section>

  <section>
    <h2>üï∂Ô∏è AR Clothing Try‚ÄëOn</h2>
    <div class="ar-container">
      <video id="video" autoplay playsinline></video>
      <canvas id="three-canvas"></canvas>
    </div>
  </section>

  <!-- Dependencies -->
  <script src="https://cdn.jsdelivr.net/npm/three@0.153.0/build/three.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/three@0.153.0/examples/js/loaders/GLTFLoader.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose@0.5/pose.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils@0.3/camera_utils.js"></script>

  <script>
    const videoElem = document.getElementById('video');
    const canvas3d = document.getElementById('three-canvas');

    // Three.js setup
    const scene = new THREE.Scene();
    const camera3d = new THREE.PerspectiveCamera(45, 640 / 480, 0.1, 1000);
    const renderer = new THREE.WebGLRenderer({ canvas: canvas3d, alpha: true });
    renderer.setSize(640, 480);
    renderer.setPixelRatio(window.devicePixelRatio);

    const ambient = new THREE.AmbientLight(0xffffff, 0.8);
    scene.add(ambient);
    const dirLight = new THREE.DirectionalLight(0xffffff, 0.5);
    dirLight.position.set(0, 1, 1);
    scene.add(dirLight);

    let shirtMesh = null;  // 3D model
    let shirtImageFallback = new Image();  // fallback for 2D img preview (optional)

    // Load model via file input
    document.getElementById('uploadModel').addEventListener('change', (e) => {
      const file = e.target.files[0];
      if (!file) return;
      const reader = new FileReader();
      const fileName = file.name.toLowerCase();
      if (fileName.endsWith('.glb') || fileName.endsWith('.gltf')) {
        reader.onload = (ev) => {
          const arrayBuffer = ev.target.result;
          const loader = new THREE.GLTFLoader();
          loader.parse(arrayBuffer, '', function(gltf) {
            if (shirtMesh) {
              scene.remove(shirtMesh);
            }
            shirtMesh = gltf.scene;
            // Optionally center and scale initial position
            shirtMesh.scale.set(1,1,1);
            scene.add(shirtMesh);
          }, function(error) {
            console.error("Error parsing 3D model:", error);
          });
        };
        reader.readAsArrayBuffer(file);
      } else {
        // fallback: PNG image
        reader.onload = (ev) => {
          shirtImageFallback.src = ev.target.result;
          document.getElementById('staticPreview').src = ev.target.result;
        };
        reader.readAsDataURL(file);
      }
    });

    camera3d.position.set(0, 0, 5);
    camera3d.lookAt(0, 0, 0);

    // Pose detection setup (MediaPipe)
    const pose = new Pose({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/pose@0.5/${file}`
    });
    pose.setOptions({
      modelComplexity: 1,
      smoothLandmarks: true,
      enableSegmentation: false,
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5
    });
    pose.onResults(onPose);

    const cameraUtils = new CameraUtils.Camera(videoElem, {
      onFrame: async () => {
        await pose.send({ image: videoElem });
      },
      width: 640,
      height: 480
    });
    cameraUtils.start();

    function onPose(results) {
      // render video is handled by video elem, Three.js draws above it
      if (!shirtMesh || !results.poseLandmarks) {
        renderer.render(scene, camera3d);
        return;
      }

      const lm = results.poseLandmarks.map(p => ({
        x: 1 - p.x,
        y: p.y,
        z: p.z,
        visibility: p.visibility
      }));

      const ls = lm[11];
      const rs = lm[12];
      const lh = lm[23];
      const rh = lm[24];

      if (ls && rs && lh && rh) {
        const w = 640, h = 480;

        const centerX = ((ls.x + rs.x) / 2 * w) - w/2;
        const centerY = -(((ls.y + rs.y) / 2 * h) - h/2);

        const hipY = ((lh.y + rh.y) / 2 * h);
        const torsoHeight = hipY - ((ls.y + rs.y) / 2 * h);

        const dx = (rs.x - ls.x) * w;
        const dy = (rs.y - ls.y) * h;
        const shoulderDist = Math.sqrt(dx * dx + dy * dy);

        const angle = Math.atan2(dy, dx);

        // Map to 3D transforms
        shirtMesh.position.set(centerX * 0.01, centerY * 0.01, 0);
        shirtMesh.scale.set(shoulderDist * 0.01, torsoHeight * 0.01, shoulderDist * 0.01);
        shirtMesh.rotation.set(0, 0, angle);
      }

      renderer.render(scene, camera3d);
    }
  </script>
</body>
</html>
