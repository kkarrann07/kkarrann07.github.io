<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>ChechIT – AR Try‑On with 3D Garment Mesh</title>
  <style>
    body, html {
      margin: 0; padding: 0; width: 100%; height: 100%;
      overflow: hidden;
      background: #f7f7f7;
      font-family: Arial, sans-serif;
    }
    header {
      background: #222; color: white; padding: 1rem; font-size: 1.5rem;
      text-align: center;
    }
    .ar-container {
      position: relative;
      width: 640px;
      height: 480px;
      margin: auto;
    }
    video {
      position: absolute;
      top: 0; left: 0;
      width: 640px; height: 480px;
      transform: scaleX(-1); /* mirror for natural selfie view */
      z-index: 1;
      object-fit: cover;
    }
    #three-canvas {
      position: absolute;
      top: 0; left: 0;
      width: 640px; height: 480px;
      z-index: 2;
      pointer-events: none;
    }
  </style>
</head>
<body>
  <header>👗 ChechIT – AR Try‑On with 3D Garment</header>
  <div class="ar-container">
    <video id="video" autoplay playsinline></video>
    <canvas id="three-canvas"></canvas>
  </div>

  <!-- Scripts: TFJS, Pose, Three.js, GLTFLoader -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>
  <script src="https://cdn.jsdelivr.net/npm/three@0.153.0/build/three.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/three@0.153.0/examples/js/loaders/GLTFLoader.js"></script>

  <script>
    const videoElem = document.getElementById('video');
    const threeCanvas = document.getElementById('three-canvas');

    let detector;

    // Three.js scene setup
    const scene = new THREE.Scene();
    const camera = new THREE.PerspectiveCamera(45, 640 / 480, 0.1, 1000);
    const renderer = new THREE.WebGLRenderer({ canvas: threeCanvas, alpha: true });
    renderer.setSize(640, 480);
    renderer.setPixelRatio(window.devicePixelRatio);

    // Lights
    const ambient = new THREE.AmbientLight(0xffffff, 0.8);
    scene.add(ambient);
    const dir = new THREE.DirectionalLight(0xffffff, 0.5);
    dir.position.set(0, 1, 1);
    scene.add(dir);

    // Load 3D shirt model
    let shirtMesh = null;
    const loader = new THREE.GLTFLoader();
    loader.load(
      'path/to/your/shirt_model.glb',  // <-- You must provide this model
      function (gltf) {
        shirtMesh = gltf.scene;
        shirtMesh.scale.set(1, 1, 1);
        scene.add(shirtMesh);
      },
      undefined,
      function (error) {
        console.error("Error loading shirt model:", error);
      }
    );

    // Position camera so it “sees” the model and video overlay
    camera.position.set(0, 0, 5);  // You may need to adjust
    camera.lookAt(0, 0, 0);

    // Start camera & pose
    async function initPose() {
      const model = poseDetection.SupportedModels.BlazePose;
      detector = await poseDetection.createDetector(model, {
        runtime: 'mediapipe',
        modelType: poseDetection.movenet.modelType.SINGLEPOSE_LIGHTNING,
        enableSmoothing: true
      });
      startVideo();
      requestAnimationFrame(renderLoop);
    }

    async function startVideo() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: { width: 640, height: 480 }, audio: false });
        videoElem.srcObject = stream;
        await videoElem.play();
      } catch (err) {
        console.error("Camera error:", err);
      }
    }

    async function renderLoop() {
      if (videoElem.readyState >= 2 && detector && shirtMesh) {
        const poses = await detector.estimatePoses(videoElem, { flipHorizontal: true });
        if (poses && poses.length > 0) {
          const p = poses[0];
          const k = p.keypoints;

          // Example: pick landmarks for shoulders, hips
          const leftShoulder = k.find(kp => kp.name === 'left_shoulder');
          const rightShoulder = k.find(kp => kp.name === 'right_shoulder');
          const leftHip = k.find(kp => kp.name === 'left_hip');
          const rightHip = k.find(kp => kp.name === 'right_hip');

          if (leftShoulder && rightShoulder && leftHip && rightHip) {
            // Convert normalized coords to screen coords
            const w = 640, h = 480;
            const ls = { x: (leftShoulder.x * w) - w/2, y: -(leftShoulder.y * h) + h/2 };
            const rs = { x: (rightShoulder.x * w) - w/2, y: -(rightShoulder.y * h) + h/2 };
            const lh = { x: (leftHip.x * w) - w/2, y: -(leftHip.y * h) + h/2 };
            const rh = { x: (rightHip.x * w) - w/2, y: -(rightHip.y * h) + h/2 };

            // Compute center and orientation of torso in 3D
            const centerX = (ls.x + rs.x) / 2;
            const centerY = (ls.y + rs.y) / 2;
            const width = Math.hypot(rs.x - ls.x, rs.y - ls.y);
            const height = ( ((lh.y + rh.y)/2) - centerY );

            // Update shirt mesh transform
            shirtMesh.position.set(centerX * 0.01, centerY * 0.01, 0);
            shirtMesh.scale.set(width * 0.01, height * 0.01, width * 0.01);
            // Optionally rotate in Z based on shoulder slope
            const angle = Math.atan2(rs.y - ls.y, rs.x - ls.x);
            shirtMesh.rotation.set(0, 0, angle);
          }
        }
      }

      renderer.render(scene, camera);
      requestAnimationFrame(renderLoop);
    }

    initPose();
  </script>
</body>
</html>
