<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>ChechIT - AI Fashion Search & AR Try-On</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      background: #f7f7f7;
      margin: 0;
      padding: 0;
      text-align: center;
    }
    header {
      background: #222;
      color: #fff;
      padding: 1rem;
      font-size: 1.4rem;
      font-weight: bold;
    }
    section {
      padding: 2rem;
    }
    iframe {
      border: none;
      border-radius: 12px;
      box-shadow: 0 4px 12px rgba(0,0,0,0.2);
    }
    .ar-container {
      position: relative;
      width: 640px;
      height: 480px;
      margin: auto;
    }
    video, canvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 640px;
      height: 480px;
      border-radius: 12px;
      transform: scaleX(-1); /* mirror flip */
    }
    input[type="file"] {
      margin-top: 10px;
    }
  </style>
</head>
<body>
  <header>
    üëó ChechIT ‚Äì AI Fashion Search + AR Try-On
  </header>

  <!-- AI Search -->
  <section>
    <h2>üîç AI Fashion Search</h2>
    <p>Use our Hugging Face-powered model to search clothing with AI embeddings.</p>
    <iframe src="https://kkarrann07-Fashion.hf.space" width="100%" height="650"></iframe>
  </section>

  <!-- Upload -->
  <section>
    <h2>üñºÔ∏è Upload Your Clothing Image</h2>
    <p>Choose a shirt/top image (preferably transparent PNG) to try it on using your camera.</p>
    <input type="file" id="upload" accept="image/*">
  </section>

  <!-- AR Try-On -->
  <section>
    <h2>üï∂Ô∏è AR Clothing Try-On</h2>
    <p>Turn on your camera. Once you upload a shirt image, it will overlay your body.</p>
    <div class="ar-container">
      <video id="video" autoplay playsinline></video>
      <canvas id="output" width="640" height="480"></canvas>
    </div>
  </section>

  <!-- MediaPipe Libraries -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose@0.5/pose.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils@0.3/camera_utils.js"></script>

  <script>
    const videoElement = document.getElementById('video');
    const canvasElement = document.getElementById('output');
    const ctx = canvasElement.getContext('2d');

    let shirt = new Image();
    let shirtLoaded = false;

    // Upload + Resize image before using
    document.getElementById('upload').addEventListener('change', (event) => {
      const file = event.target.files[0];
      if (!file) return;

      const reader = new FileReader();

      reader.onload = function (e) {
        const uploadedImage = new Image();
        uploadedImage.onload = () => {
          const offCanvas = document.createElement('canvas');
          const maxSize = 512;
          const ratio = Math.min(maxSize / uploadedImage.width, maxSize / uploadedImage.height);
          offCanvas.width = uploadedImage.width * ratio;
          offCanvas.height = uploadedImage.height * ratio;

          const offCtx = offCanvas.getContext('2d');
          offCtx.clearRect(0, 0, offCanvas.width, offCanvas.height);
          offCtx.drawImage(uploadedImage, 0, 0, offCanvas.width, offCanvas.height);

          // Use resized version
          shirt.src = offCanvas.toDataURL("image/png");
        };
        uploadedImage.onerror = () => {
          shirtLoaded = false;
          alert("Could not load the image. Try another PNG.");
        };
        uploadedImage.src = e.target.result;
      };

      reader.readAsDataURL(file);
    });

    shirt.onload = () => {
      shirtLoaded = true;
    };

    // Initialize MediaPipe Pose
    const pose = new Pose({
      locateFile: file => `https://cdn.jsdelivr.net/npm/@mediapipe/pose@0.5/${file}`
    });

    pose.setOptions({
      modelComplexity: 1,
      smoothLandmarks: true,
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5
    });

    pose.onResults(results => {
      ctx.save();
      ctx.clearRect(0, 0, canvasElement.width, canvasElement.height);

      // Flip canvas to match mirrored camera
      ctx.scale(-1, 1);
      ctx.translate(-canvasElement.width, 0);

      ctx.drawImage(results.image, 0, 0, canvasElement.width, canvasElement.height);

      if (results.poseLandmarks && shirtLoaded) {
        const lm = results.poseLandmarks;
        const w = canvasElement.width;
        const h = canvasElement.height;

        const leftShoulder = lm[11];
        const rightShoulder = lm[12];
        const leftHip = lm[23];
        const rightHip = lm[24];

        const torsoWidth = Math.abs(rightShoulder.x - leftShoulder.x) * w;
        const shoulderCenterX = ((leftShoulder.x + rightShoulder.x) / 2) * w;
        const shoulderCenterY = ((leftShoulder.y + rightShoulder.y) / 2) * h;
        const hipCenterY = ((leftHip.y + rightHip.y) / 2) * h;
        const torsoHeight = Math.abs(hipCenterY - shoulderCenterY);

        const widthScale = 1.5;
        const heightScale = 2.2;

        const finalWidth = torsoWidth * widthScale;
        const finalHeight = torsoHeight * heightScale;

        const x = shoulderCenterX - (finalWidth / 2);
        const y = shoulderCenterY - (torsoHeight * 0.2);

        ctx.drawImage(shirt, x, y, finalWidth, finalHeight);
      }

      ctx.restore();
    });

    // Start webcam
    const camera = new Camera(videoElement, {
      onFrame: async () => {
        await pose.send({ image: videoElement });
      },
      width: 640,
      height: 480
    });

    camera.start();
  </script>
</body>
</html>
