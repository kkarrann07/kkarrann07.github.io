<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>ChechIT - AI Fashion Try-On (OpenCV + MoveNet)</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      background: #f7f7f7;
      margin: 0;
      padding: 0;
      text-align: center;
    }
    header {
      background: #222;
      color: #fff;
      padding: 1rem;
      font-size: 1.4rem;
      font-weight: bold;
    }
    section {
      padding: 1rem 2rem 3rem 2rem;
    }
    .ar-container {
      position: relative;
      width: 640px;
      height: 480px;
      margin: auto;
    }
    video {
      position: absolute;
      top: 0;
      left: 0;
      width: 640px;
      height: 480px;
      border-radius: 12px;
      transform: scaleX(-1); /* mirror camera for natural selfie */
      z-index: 1;
    }
    canvas#outputCanvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 640px;
      height: 480px;
      border-radius: 12px;
      z-index: 2;
      /* no mirror on canvas */
    }
    input[type="file"] {
      margin-top: 10px;
    }
    .static-shirt {
      margin-top: 1rem;
      perspective: 800px;
      width: 320px;
      margin-left: auto;
      margin-right: auto;
      user-select: none;
    }
    .rotator {
      width: 100%;
      height: 400px;
      border-radius: 12px;
      border: 1px solid #ccc;
      overflow: hidden;
      background: #fff;
      display: flex;
      justify-content: center;
      align-items: center;
      cursor: grab;
      transition: transform 0.1s ease-out;
    }
    .rotator img {
      max-width: 100%;
      max-height: 100%;
      pointer-events: none;
      user-select: none;
      border-radius: 12px;
      backface-visibility: hidden;
      transform-style: preserve-3d;
    }
    .rotator:active {
      cursor: grabbing;
    }
  </style>
</head>
<body>
  <header>üëó ChechIT ‚Äì AI Fashion Try-On (OpenCV + MoveNet)</header>

  <section>
    <h2>Upload Your Shirt Image</h2>
    <input type="file" id="upload" accept="image/*" />
    <div class="static-shirt" aria-label="Static Shirt Viewer">
      <p>üñºÔ∏è Preview (3D Rotator):</p>
      <div class="rotator" id="rotator">
        <img id="staticPreview" src="" alt="Uploaded shirt preview" />
      </div>
    </div>
  </section>

  <section>
    <h2>AR Try-On</h2>
    <p>Allow camera access and watch the shirt overlay on your torso.</p>
    <div class="ar-container">
      <video id="video" autoplay playsinline></video>
      <canvas id="outputCanvas" width="640" height="480"></canvas>
    </div>
  </section>

  <!-- TensorFlow.js and MoveNet Model -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.9.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection/dist/movenet.min.js"></script>

  <!-- OpenCV.js -->
  <script async src="https://docs.opencv.org/4.x/opencv.js" onload="onOpenCvReady();" ></script>

  <script>
    let video = document.getElementById('video');
    let outputCanvas = document.getElementById('outputCanvas');
    let ctx = outputCanvas.getContext('2d');

    let shirt = new Image();
    let shirtLoaded = false;

    let staticPreview = document.getElementById('staticPreview');
    let rotator = document.getElementById('rotator');
    let rotationY = 0, isDragging = false, startX = 0;

    // Load shirt image from upload
    document.getElementById('upload').addEventListener('change', e => {
      const file = e.target.files[0];
      if (!file) return;
      const reader = new FileReader();
      reader.onload = ev => {
        const img = new Image();
        img.onload = () => {
          // Resize shirt if too big
          const maxSize = 512;
          const ratio = Math.min(maxSize / img.width, maxSize / img.height, 1);
          const offCanvas = document.createElement('canvas');
          offCanvas.width = img.width * ratio;
          offCanvas.height = img.height * ratio;
          const offCtx = offCanvas.getContext('2d');
          offCtx.clearRect(0, 0, offCanvas.width, offCanvas.height);
          offCtx.drawImage(img, 0, 0, offCanvas.width, offCanvas.height);
          shirt.src = offCanvas.toDataURL("image/png");
          staticPreview.src = shirt.src;
          shirtLoaded = true;
        };
        img.src = ev.target.result;
      };
      reader.readAsDataURL(file);
    });

    // Rotator handlers for static preview
    rotator.addEventListener('mousedown', (e) => {
      isDragging = true;
      startX = e.clientX;
      rotator.style.cursor = 'grabbing';
    });
    rotator.addEventListener('mouseup', () => {
      isDragging = false;
      rotator.style.cursor = 'grab';
    });
    rotator.addEventListener('mouseleave', () => {
      isDragging = false;
      rotator.style.cursor = 'grab';
    });
    rotator.addEventListener('mousemove', (e) => {
      if (!isDragging) return;
      let deltaX = e.clientX - startX;
      startX = e.clientX;
      rotationY += deltaX * 0.5;
      rotationY %= 360;
      staticPreview.style.transform = `rotateY(${rotationY}deg)`;
    });
    rotator.addEventListener('touchstart', e => {
      isDragging = true;
      startX = e.touches[0].clientX;
      rotator.style.cursor = 'grabbing';
    });
    rotator.addEventListener('touchend', e => {
      isDragging = false;
      rotator.style.cursor = 'grab';
    });
    rotator.addEventListener('touchcancel', e => {
      isDragging = false;
      rotator.style.cursor = 'grab';
    });
    rotator.addEventListener('touchmove', e => {
      if (!isDragging) return;
      let deltaX = e.touches[0].clientX - startX;
      startX = e.touches[0].clientX;
      rotationY += deltaX * 0.5;
      rotationY %= 360;
      staticPreview.style.transform = `rotateY(${rotationY}deg)`;
    });

    // OpenCV.js ready flag
    let cvReady = false;
    function onOpenCvReady() {
      cvReady = true;
      console.log('OpenCV.js is ready');
      if (detectorReady) startVideo();
    }

    // Tensorflow MoveNet detector
    let detector, detectorReady = false;

    async function createDetector() {
      const model = poseDetection.SupportedModels.MoveNet;
      detector = await poseDetection.createDetector(model, {
        modelType: poseDetection.movenet.modelType.SINGLEPOSE_LIGHTNING
      });
      detectorReady = true;
      console.log('MoveNet detector ready');
      if (cvReady) startVideo();
    }

    createDetector();

    // Start video and processing
    async function startVideo() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: { width: 640, height: 480 }, audio: false });
        video.srcObject = stream;
        video.play();
        requestAnimationFrame(processFrame);
      } catch (err) {
        alert('Error accessing camera: ' + err.message);
      }
    }

    async function processFrame() {
      if (video.readyState < 2 || !shirtLoaded) {
        requestAnimationFrame(processFrame);
        return;
      }

      // Get pose estimation
      const poses = await detector.estimatePoses(video, { flipHorizontal: true });
      ctx.clearRect(0, 0, outputCanvas.width, outputCanvas.height);

      // Draw mirrored video frame on canvas normally (no mirror here because video is mirrored by CSS)
      ctx.save();
      ctx.scale(-1, 1);
      ctx.drawImage(video, -outputCanvas.width, 0, outputCanvas.width, outputCanvas.height);
      ctx.restore();

      if (poses.length > 0) {
        const keypoints = poses[0].keypoints;

        // Get relevant keypoints (left/right shoulder, left/right hip)
        const leftShoulder = keypoints.find(k => k.name === 'left_shoulder');
        const rightShoulder = keypoints.find(k => k.name === 'right_shoulder');
        const leftHip = keypoints.find(k => k.name === 'left_hip');
        const rightHip = keypoints.find(k => k.name === 'right_hip');

        if ([leftShoulder, rightShoulder, leftHip, rightHip].some(p => p == null || p.score < 0.4)) {
          requestAnimationFrame(processFrame);
          return;
        }

        // Use OpenCV.js to do affine transform and overlay shirt

        // Convert points to cv.Point2
        const ptsSrc = cv.matFromArray(3, 1, cv.CV_32FC2, [
          0, 0, // shirt image top-left
          shirt.width, 0, // shirt image top-right
          0, shirt.height // shirt image bottom-left
        ]);

        // Calculate destination points on the canvas using detected keypoints:
        // Map shirt top-left to left shoulder
        // Map shirt top-right to right shoulder
        // Map shirt bottom-left to midpoint between left hip and right hip (approx. torso bottom)

        const dstLeftShoulder = new cv.Point(outputCanvas.width - leftShoulder.x * outputCanvas.width, leftShoulder.y * outputCanvas.height);
        const dstRightShoulder = new cv.Point(outputCanvas.width - rightShoulder.x * outputCanvas.width, rightShoulder.y * outputCanvas.height);
        const hipMidX = (leftHip.x + rightHip.x) / 2;
        const hipMidY = (leftHip.y + rightHip.y) / 2;
        const dstHipMid = new cv.Point(outputCanvas.width - hipMidX * outputCanvas.width, hipMidY * outputCanvas.height);

        const ptsDst = cv.matFromArray(3, 1, cv.CV_32FC2, [
          dstLeftShoulder.x, dstLeftShoulder.y,
          dstRightShoulder.x, dstRightShoulder.y,
          dstHipMid.x, dstHipMid.y
        ]);

        // Get affine transform matrix
        let M = cv.getAffineTransform(ptsSrc, ptsDst);

        // Create src Mat from shirt image
        let src = cv.imread(shirt);

        // Create destination Mat with transparent background
        let dst = new cv.Mat.zeros(outputCanvas.height, outputCanvas.width, cv.CV_8UC4);

        // Warp the shirt image onto dst Mat using affine transform
        cv.warpAffine(src, dst, M, new cv.Size(outputCanvas.width, outputCanvas.height), cv.INTER_LINEAR, cv.BORDER_CONSTANT, new cv.Scalar(0,0,0,0));

        // Convert dst Mat to ImageData and draw on canvas
        let imgData = new ImageData(new Uint8ClampedArray(dst.data), dst.cols, dst.rows);

        ctx.putImageData(imgData, 0, 0);

        // Cleanup
        ptsSrc.delete();
        ptsDst.delete();
        M.delete();
        src.delete();
        dst.delete();
      }

      requestAnimationFrame(processFrame);
    }
  </script>
</body>
</html>
